# export UTILS_DIR="/home/zhuotaotian/psp/llm/utils"
# export HF_HOME="${UTILS_DIR}/models"
# export MODEL_PATH="${UTILS_DIR}/models/hub"

# export HF_HOME="/home/yilin/.cache/huggingface"
# export MODEL_PATH="${HF_HOME}/hub"

# Choose which GPU(s) to use
export CUDA_VISIBLE_DEVICES=2,3

# 设置 Hugging Face 的镜像地址（如果 hf-mirrir 没有挂的话）
# export HF_ENDPOINT=https://hf-mirror.com
# export HF_ENDPOINT=https://huggingface.co

# 设置 HTTP 和 HTTPS 代理
# export http_proxy=http://127.0.0.1:7890
# export https_proxy=http://127.0.0.1:7890
# git config --global http.proxy http://127.0.0.1:7890
# git config --global https.proxy http://127.0.0.1:7890
# export http_proxy=''
# export https_proxy=''

# export TORCH_CUDA_ARCH_LIST="8.0"
# export ACCELERATE_LOG_LEVEL="info"
# export TRANSFORMERS_OFFLINE=0
# export HF_DATASETS_OFFLINE=0
# export HF_HUB_OFFLINE=0

# 设置不通过代理的地址
# export no_proxy="127.0.0.1,localhost,*.cnn.com,192.168.1.10,domain.com:8080"

## When debugging, open the following line
# export VLLM_LOGGING_LEVEL=DEBUG
# export CUDA_LAUNCH_BLOCKING=1
# export NCCL_DEBUG=TRACE
# export VLLM_TRACE_FUNCTION=1

# 自定义 vllm 的日志
export VLLM_CONFIGURE_LOGGING=1
export VLLM_LOGGING_CONFIG_PATH="./utils/vllm_logging_config.json"
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# VLLM_ATTENTION_BACKEND=FLASH_ATTN
# 禁用 tqdm
# TQDM_DISABLE=1
