from dataclasses import dataclass, field

from PIL import Image

from model.detector.yolo_model import YoloResult

from .dataset import DataPoint


@dataclass
class DataState:
    data: DataPoint
    image_path: str = field(init=False)
    image: Image.Image = field(init=False)
    question: str = field(init=False)
    is_finished: bool = False
    assistant: str = ""
    # To cache three types of objects
    nonhallu_objects: list[str] = field(default_factory=list)
    uncertain_objects: list[str] = field(default_factory=list)
    hallu_objects: list[str] = field(default_factory=list)

    def __post_init__(self):
        from run.utils import open_images

        self.image_path = self.data.image_path
        self.image = open_images(self.image_path)
        self.question = self.data.question


@dataclass
class DataStateForBuildDataset(DataState):
    # For building Desc dataset
    yolo_detected: bool = False
    yolo_result: YoloResult = None

    # To cache which detcetor reject which object
    detector_reject: dict[str, list[str]] = field(init=False)
    # To cache all sentences generated by the generator, each element is a list of sentences of step i
    generated_sentences: list[list[str]] = field(default_factory=list)
    # To cache the assistent sentence of the generator, each element indicates the assistant sentence of step i, the lenth is the number of sentences generated
    generated_assistents: list[str] = field(default_factory=list)

    # To cache all objects generated by the generator, each element is a list of objects of step i
    generated_objects: list[list[list[str]]] = field(default_factory=list)
    # To cache all halluci objects generated by the generator, each element is a list of halluci objects of step i
    generated_hallu_objects: list[list[list[str]]] = field(default_factory=list)
    # To cache all non-halluci objects generated by the generator, each element is a list of non-halluci objects of step i
    generated_nonhallu_objects: list[list[list[str]]] = field(default_factory=list)

    # To cache the objects of the assistant
    assistant_objects: list[str] = field(default_factory=list)
    assistant_hallu_objects: list[str] = field(default_factory=list)
    assistant_nonhallu_objects: list[str] = field(default_factory=list)

    # For building POPE dataset
    ground_truth: bool = field(init=False)

    # Just for debugging
    gt_objects: list[str] = field(default_factory=list)

    # For hard positive data
    hard_positive: list[str] = field(default_factory=list)
    small_objects: list[str] = field(default_factory=list)
    edge_objects: list[str] = field(default_factory=list)

    # For cache nature context, the assistant sentences are generated use greddy search
    nature_context: str = None
    nature_objects: list[list[str]] = field(default_factory=list)
    nature_hallu_objects: list[list[str]] = field(default_factory=list)
    nature_nonhallu_objects: list[list[str]] = field(default_factory=list)

    def __post_init__(self):
        super().__post_init__()
        self.generated_assistents.append("")  # Necessary for the first step
        self.detector_reject = {"dino": [], "yolo": []}

        if "ground_truth" in self.data.attributes:
            self.ground_truth = self.data.attributes["ground_truth"]

    def app_assistant(self, new_sents: list[str], idx: int) -> None:
        self.assistant = self.assistant + " " + new_sents[idx] if self.assistant else new_sents[idx]
        self.generated_assistents.append(self.assistant)

        if len(self.generated_objects) == self.gen_sents_cnt:  # In case of any error
            self.assistant_objects.extend(self.generated_objects[-1][idx])
        if len(self.generated_hallu_objects) == self.gen_sents_cnt:
            self.assistant_hallu_objects.extend(self.generated_hallu_objects[-1][idx])
        if len(self.generated_nonhallu_objects) == self.gen_sents_cnt:
            self.assistant_nonhallu_objects.extend(self.generated_nonhallu_objects[-1][idx])

    @property
    def gen_sents_cnt(self) -> int:
        """Return the number of generated sentences"""
        return len(self.generated_sentences)

    @property
    def now_step_idx(self) -> int:
        """Return the index of the current step"""
        return self.gen_sents_cnt - 1

    @property
    def is_in_the_first_step(self) -> bool:
        """Return True if the current step is in the first step of generation."""
        return self.gen_sents_cnt <= 1

    @property
    def context_gen_objects(self) -> set[str]:
        return set(self.assistant_objects)

    @property
    def context_gen_hallu_objects(self) -> set[str]:
        return set(self.assistant_hallu_objects)

    def is_last_sent(self, index: int) -> bool:
        return index == self.gen_sents_cnt - 1

    def gen_sents(self, index: int) -> list[str]:
        return self.generated_sentences[index]

    def assist(self, index: int) -> str:
        return self.generated_assistents[index]

    @property
    def flat_gen_objs(self) -> list[str]:
        """返回生成的所有物体，未去重"""
        return [obj for objs in self.generated_objects for obj_list in objs for obj in obj_list]

    def gen_objs(self, index: int) -> list[list[str]]:
        return self.generated_objects[index]

    @property
    def flat_hallu_objs(self) -> list[str]:
        """返回生成的所有幻觉物体，未去重"""
        return [obj for objs in self.generated_hallu_objects for obj_list in objs for obj in obj_list]

    def hallu_objs(self, index: int) -> list[list[str]]:
        return self.generated_hallu_objects[index]

    @property
    def flat_nonhallu_objs(self) -> list[str]:
        """返回生成的所有非幻觉物体，未去重"""
        return [obj for objs in self.generated_nonhallu_objects for obj_list in objs for obj in obj_list]

    def nonhallu_objs(self, index: int) -> list[list[str]]:
        return self.generated_nonhallu_objects[index]

    @property
    def next_step_assist_from_nature_context(self) -> str:
        sent = self.nature_context.split(".")[self.now_step_idx] + "."
        return sent.lstrip(" ")

    def get_step_assist_from_nature_context(self, index: int) -> str:
        sent = self.nature_context.split(".")[index] + "."
        return sent.lstrip(" ") if sent != "." else ""
