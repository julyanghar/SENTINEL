# SENTINEL é¡¹ç›®ä»£ç è¯¦ç»†è§£è¯»ä¸æ³¨é‡Š

## ğŸ“‹ ç›®å½•
1. [é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
2. [æ•´ä½“æ¶æ„](#2-æ•´ä½“æ¶æ„)
3. [æ ¸å¿ƒæ¨¡å—è¯¦è§£](#3-æ ¸å¿ƒæ¨¡å—è¯¦è§£)
   - [3.1 ä¸»å…¥å£æ¨¡å—](#31-ä¸»å…¥å£æ¨¡å—-mainpy)
   - [3.2 å…¨å±€å˜é‡ç®¡ç†](#32-å…¨å±€å˜é‡ç®¡ç†-modelauxiliaryglobal_varspy)
   - [3.3 æ•°æ®é›†æ¨¡å—](#33-æ•°æ®é›†æ¨¡å—-modelauxiliarydatasetpy)
   - [3.4 æ•°æ®çŠ¶æ€ç®¡ç†](#34-æ•°æ®çŠ¶æ€ç®¡ç†-modelauxiliarydatastatepy)
   - [3.5 è¿è¡Œå…¥å£](#35-è¿è¡Œå…¥å£-runrunpy)
   - [3.6 æ•°æ®é›†ç”Ÿæˆæ ¸å¿ƒ](#36-æ•°æ®é›†ç”Ÿæˆæ ¸å¿ƒ-rungenerate_datasetpy)
   - [3.7 å·¥å…·å‡½æ•°](#37-å·¥å…·å‡½æ•°-runutilspy)
4. [æ¨¡å‹æ¨¡å—è¯¦è§£](#4-æ¨¡å‹æ¨¡å—è¯¦è§£)
   - [4.1 è§†è§‰è¯­è¨€æ¨¡å‹ç”Ÿæˆå™¨](#41-è§†è§‰è¯­è¨€æ¨¡å‹ç”Ÿæˆå™¨)
   - [4.2 ç›®æ ‡æ£€æµ‹å™¨](#42-ç›®æ ‡æ£€æµ‹å™¨)
   - [4.3 NLPå·¥å…·](#43-nlpå·¥å…·)
5. [æ•°æ®æµç¨‹å›¾](#5-æ•°æ®æµç¨‹å›¾)
6. [å…³é”®ç®—æ³•è§£æ](#6-å…³é”®ç®—æ³•è§£æ)

---

## 1. é¡¹ç›®æ¦‚è¿°

**SENTINEL** (Sentence-Level Early Intervention) æ˜¯ä¸€ä¸ªç”¨äºç¼“è§£å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLMs)ä¸­å¯¹è±¡å¹»è§‰é—®é¢˜çš„é¡¹ç›®ã€‚è¯¥é¡¹ç›®é€šè¿‡ä»¥ä¸‹æ ¸å¿ƒæ€æƒ³å·¥ä½œï¼š

### æ ¸å¿ƒæ€æƒ³
1. **æ—©æœŸå¹²é¢„é˜»æ­¢å¹»è§‰ä¼ æ’­**ï¼šå¹»è§‰é€šå¸¸åœ¨æ—©æœŸå¥å­ä¸­äº§ç”Ÿå¹¶ä¼ æ’­åˆ°åç»­è¾“å‡º
2. **æ— éœ€äººå·¥æ ‡æ³¨çš„åå¥½å­¦ä¹ **ï¼šé€šè¿‡æ£€æµ‹å™¨äº¤å‰éªŒè¯æ„å»ºå¹»è§‰/çœŸå®æ ·æœ¬
3. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åå¥½æ•°æ®æ„å»º**ï¼šæ„å»ºcontext-awareçš„DPOè®­ç»ƒæ•°æ®

### ä¸»è¦åŠŸèƒ½
- è‡ªåŠ¨ç”Ÿæˆç”¨äºDPOè®­ç»ƒçš„åå¥½æ•°æ®å¯¹
- æ”¯æŒå¤šç§è§†è§‰è¯­è¨€æ¨¡å‹ (LLaVA, Qwen2-VL, Qwen2.5-VL)
- ä½¿ç”¨YOLOå’ŒGrounding DINOè¿›è¡Œå¯¹è±¡æ£€æµ‹éªŒè¯

---

## 2. æ•´ä½“æ¶æ„

```
SENTINEL/
â”œâ”€â”€ main.py                 # ä¸»å…¥å£æ–‡ä»¶
â”œâ”€â”€ run/                    # è¿è¡Œé€»è¾‘æ¨¡å—
â”‚   â”œâ”€â”€ run.py              # è¿è¡Œå…¥å£
â”‚   â”œâ”€â”€ generate_dataset.py # æ•°æ®é›†ç”Ÿæˆæ ¸å¿ƒé€»è¾‘
â”‚   â”œâ”€â”€ utils.py            # è¿è¡Œå·¥å…·å‡½æ•°
â”‚   â””â”€â”€ object_utils.py     # å¯¹è±¡å¤„ç†å·¥å…·
â”œâ”€â”€ model/                  # æ¨¡å‹æ¨¡å—
â”‚   â”œâ”€â”€ auxiliary/          # è¾…åŠ©ç±»
â”‚   â”‚   â”œâ”€â”€ global_vars.py  # å…¨å±€å˜é‡ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ dataset.py      # æ•°æ®é›†ç±»
â”‚   â”‚   â””â”€â”€ datastate.py    # æ•°æ®çŠ¶æ€ç±»
â”‚   â”œâ”€â”€ generator/          # ç”Ÿæˆå™¨æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ llava.py        # LLaVAæ¨¡å‹å°è£…
â”‚   â”‚   â”œâ”€â”€ qwen2_vl.py     # Qwen2-VLæ¨¡å‹å°è£…
â”‚   â”‚   â””â”€â”€ qwen2_5_vl.py   # Qwen2.5-VLæ¨¡å‹å°è£…
â”‚   â”œâ”€â”€ detector/           # æ£€æµ‹å™¨æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ grounding_dino.py # Grounding DINOæ£€æµ‹å™¨
â”‚   â”‚   â””â”€â”€ yolo_model.py   # YOLOæ£€æµ‹å™¨
â”‚   â”œâ”€â”€ others/             # å…¶ä»–NLPå·¥å…·
â”‚   â”‚   â”œâ”€â”€ spacy_model.py  # Spacy NLPæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ wordnet.py      # WordNetè¯æ±‡å·¥å…·
â”‚   â”‚   â””â”€â”€ sg_parser.py    # åœºæ™¯å›¾è§£æå™¨
â”‚   â””â”€â”€ utils/              # æ¨¡å‹å·¥å…·
â”‚       â”œâ”€â”€ gen_utils.py    # ç”Ÿæˆå·¥å…·å‡½æ•°
â”‚       â””â”€â”€ utils.py        # é€šç”¨å·¥å…·å‡½æ•°
â”œâ”€â”€ utils/                  # é€šç”¨å·¥å…·
â”‚   â”œâ”€â”€ setup_utils.py      # é…ç½®å’Œå‚æ•°è§£æ
â”‚   â”œâ”€â”€ get_llama_factory_data_pair.py  # æ•°æ®æ ¼å¼è½¬æ¢
â”‚   â””â”€â”€ .env                # ç¯å¢ƒå˜é‡é…ç½®
â””â”€â”€ train/                  # è®­ç»ƒç›¸å…³ä»£ç 
```

---

## 3. æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 3.1 ä¸»å…¥å£æ¨¡å— (main.py)

```python
"""
main.py - ç¨‹åºä¸»å…¥å£

è¿™æ˜¯æ•´ä¸ªSENTINELé¡¹ç›®çš„å¯åŠ¨æ–‡ä»¶ï¼Œè´Ÿè´£ï¼š
1. åŠ è½½ç¯å¢ƒå˜é‡é…ç½®
2. åˆå§‹åŒ–å…¨å±€å˜é‡
3. å¯åŠ¨æ•°æ®ç”Ÿæˆæµç¨‹
"""

from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡é…ç½®
# åŒ…æ‹¬æ¨¡å‹è·¯å¾„ã€HuggingFaceç›®å½•ç­‰å…³é”®é…ç½®
print("Load dot env result:", load_dotenv("./utils/.env"))


def main():
    """
    ä¸»å‡½æ•°å…¥å£
    
    æ‰§è¡Œæµç¨‹ï¼š
    1. å¯¼å…¥å¹¶åˆå§‹åŒ–å…¨å±€å˜é‡ç±» GVars
    2. è°ƒç”¨ run() å‡½æ•°å¯åŠ¨æ•°æ®ç”Ÿæˆæµç¨‹
    """
    # å¯¼å…¥å…¨å±€å˜é‡ç®¡ç†ç±»
    from model.auxiliary.global_vars import GVars

    # åˆå§‹åŒ–å…¨å±€å˜é‡ï¼ˆåŒ…æ‹¬å‚æ•°è§£æã€æ—¥å¿—é…ç½®ã€è®¾å¤‡æ£€æµ‹ç­‰ï¼‰
    GVars.init()

    # å¯¼å…¥å¹¶æ‰§è¡Œä¸»è¿è¡Œé€»è¾‘
    from run.run import run
    run()


if __name__ == "__main__":
    main()
```

---

### 3.2 å…¨å±€å˜é‡ç®¡ç† (model/auxiliary/global_vars.py)

```python
"""
global_vars.py - å…¨å±€å˜é‡ç®¡ç†ç±»

è¿™ä¸ªæ¨¡å—å®šä¹‰äº†ä¸€ä¸ªå•ä¾‹æ¨¡å¼çš„å…¨å±€å˜é‡ç®¡ç†ç±» GVarsï¼Œç”¨äºï¼š
1. ç®¡ç†å‘½ä»¤è¡Œå‚æ•°
2. é…ç½®æ—¥å¿—ç³»ç»Ÿ
3. ç®¡ç†æ¨¡å‹ç›®å½•å’Œè®¾å¤‡ä¿¡æ¯
4. æä¾›å…¨å±€å…±äº«çš„é…ç½®ä¿¡æ¯
"""

import logging
import os
import sys
from argparse import Namespace
from logging import Logger

import torch
from utils.setup_utils import get_save_path, parse_arg


class GVars:
    """
    å…¨å±€å˜é‡ç®¡ç†ç±» (å•ä¾‹æ¨¡å¼)
    
    ç±»å±æ€§ï¼ˆæ‰€æœ‰å®ä¾‹å…±äº«ï¼‰ï¼š
    - args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡
    - save_path: ç»“æœä¿å­˜è·¯å¾„
    - model_dir: æ¨¡å‹ç¼“å­˜ç›®å½•
    - hf_home: HuggingFace ä¸»ç›®å½•
    - gpu_count: GPUæ•°é‡
    - device: é»˜è®¤è®¾å¤‡
    - main_device: ä¸»GPUè®¾å¤‡
    - alter_device: å¤‡ç”¨GPUè®¾å¤‡ï¼ˆç”¨äºè¾…åŠ©æ¨¡å‹ï¼‰
    - openai_key: OpenAI APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
    - logger: æ—¥å¿—è®°å½•å™¨
    """
    args: Namespace | None = None          # å‘½ä»¤è¡Œå‚æ•°
    save_path: str | None = None           # ç»“æœä¿å­˜è·¯å¾„
    model_dir: str | None = None           # æ¨¡å‹ç¼“å­˜ç›®å½•
    hf_home: str | None = None             # HuggingFace Homeç›®å½•
    gpu_count: int | None = None           # å¯ç”¨GPUæ•°é‡
    device: str | None = None              # é»˜è®¤è®¡ç®—è®¾å¤‡
    main_device: str | None = None         # ä¸»GPUï¼ˆè¿è¡Œç”Ÿæˆå™¨ï¼‰
    alter_device: str | None = None        # å¤‡ç”¨GPUï¼ˆè¿è¡Œæ£€æµ‹å™¨ç­‰ï¼‰
    openai_key: str | None = None          # OpenAI APIå¯†é’¥
    logger: Logger = logging.getLogger()   # æ—¥å¿—è®°å½•å™¨

    @classmethod
    def init(cls, save: bool = True) -> None:
        """
        åˆå§‹åŒ–æ‰€æœ‰å…¨å±€å˜é‡
        
        å‚æ•°:
            save: æ˜¯å¦åˆå§‹åŒ–ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ä¸ºTrue
        
        åˆå§‹åŒ–é¡ºåºå¾ˆé‡è¦ï¼š
        1. é¦–å…ˆè§£æå‘½ä»¤è¡Œå‚æ•°
        2. é…ç½®æ—¥å¿—ç³»ç»Ÿ
        3. è®¾ç½®æ¨¡å‹ç›®å½•
        4. ç¡®å®šä¿å­˜è·¯å¾„
        5. æ£€æµ‹å¹¶é…ç½®è®¾å¤‡
        6. åŠ è½½å¯é€‰çš„APIå¯†é’¥
        """
        cls.init_args()
        cls.init_logger()
        cls.init_model_dir()
        if save:
            cls.init_save_file_path()
        cls.init_device()
        cls.init_openai_key()
        cls.logger.info("Global variables (Gvars) have been initialized")

    @classmethod
    def init_args(cls, alter: dict | None = None) -> None:
        """
        è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶å­˜å‚¨
        
        å‚æ•°:
            alter: å¯é€‰çš„å‚æ•°è¦†ç›–å­—å…¸ï¼Œç”¨äºæµ‹è¯•æˆ–ç‰¹æ®Šåœºæ™¯
        """
        cls.args = parse_arg()
        if alter is not None:
            for key in alter:
                if alter[key]:
                    setattr(cls.args, key, alter[key])

    @classmethod
    def init_model_dir(cls) -> None:
        """
        ä»ç¯å¢ƒå˜é‡ä¸­è·å–æ¨¡å‹ç›®å½•é…ç½®
        
        ç¯å¢ƒå˜é‡:
            HF_HOME: HuggingFaceç¼“å­˜ä¸»ç›®å½•
            MODEL_PATH: è‡ªå®šä¹‰æ¨¡å‹å­˜å‚¨è·¯å¾„
        """
        cls.hf_home = os.getenv("HF_HOME")
        cls.model_dir = os.getenv("MODEL_PATH")

    @classmethod
    def init_device(cls) -> None:
        """
        è‡ªåŠ¨æ£€æµ‹å¹¶é…ç½®è®¡ç®—è®¾å¤‡
        
        è®¾å¤‡åˆ†é…ç­–ç•¥ï¼š
        - æ— GPU: ä½¿ç”¨CPU
        - å•GPU: ä¸»è®¾å¤‡å’Œå¤‡ç”¨è®¾å¤‡éƒ½ä½¿ç”¨åŒä¸€GPU
        - å¤šGPU: ä¸»æ¨¡å‹ä½¿ç”¨cuda:0ï¼Œè¾…åŠ©æ¨¡å‹ä½¿ç”¨cuda:1
        
        è¿™ç§åˆ†é…å¯ä»¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œé¿å…ç”Ÿæˆå™¨å’Œæ£€æµ‹å™¨æŠ¢å æ˜¾å­˜
        """
        if not torch.cuda.is_available():
            cls.main_device, cls.alter_device, cls.gpu_count = "cpu", "cpu", 0
        elif torch.cuda.device_count() == 1:
            cls.main_device, cls.alter_device, cls.gpu_count = "cuda:0", "cuda:0", 1
        else:
            # å¤šGPUæ—¶åˆ†ç¦»ä¸»æ¨¡å‹å’Œè¾…åŠ©æ¨¡å‹
            cls.main_device, cls.alter_device, cls.gpu_count = "cuda:0", "cuda:1", 2
        cls.device = cls.main_device

    @classmethod
    def init_logger(cls) -> None:
        """
        é…ç½®æ—¥å¿—ç³»ç»Ÿ
        
        ç‰¹ç‚¹ï¼š
        - åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
        - æ—¥å¿—æ–‡ä»¶ååŒ…å«æ¨¡å‹åç§°å’Œæ•°æ®é‡ä¿¡æ¯
        - é…ç½®Transformersåº“çš„æ—¥å¿—çº§åˆ«
        """
        from logging import INFO, WARNING
        from transformers.utils import logging as transformers_logging

        _nameToLevel = {"WARNING": WARNING, "INFO": INFO}

        cls.logger.setLevel(_nameToLevel["INFO"])
        args = cls.args
        
        # æ—¥å¿—æ–‡ä»¶å‘½å: æ¨¡å‹å-æ•°æ®é‡.log
        log_filename = f"{args.model}-{args.num_of_data}.log"
        log_path = os.path.join(args.log_dir, log_filename)

        os.makedirs(args.log_dir, exist_ok=True)

        # é…ç½®æ—¥å¿—æ ¼å¼å’Œå¤„ç†å™¨
        logging.basicConfig(
            format="[%(levelname)s|%(filename)s:%(lineno)s] %(asctime)s >> %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            handlers=[
                logging.StreamHandler(sys.stdout),           # æ§åˆ¶å°è¾“å‡º
                logging.FileHandler(log_path, mode="a"),     # æ–‡ä»¶è¾“å‡º
            ],
        )
        
        # é…ç½®Transformersåº“æ—¥å¿—
        transformers_logging.set_verbosity(_nameToLevel[args.log_level])
        transformers_logging.enable_default_handler()
        transformers_logging.add_handler(logging.FileHandler(log_path, mode="a"))
        transformers_logging.enable_explicit_format()
```

---

### 3.3 æ•°æ®é›†æ¨¡å— (model/auxiliary/dataset.py)

```python
"""
dataset.py - æ•°æ®é›†ç®¡ç†æ¨¡å—

å®šä¹‰äº†æ•°æ®ç‚¹(DataPoint)å’Œæ•°æ®é›†(DataSet)ç±»ï¼Œç”¨äºï¼š
1. åŠ è½½å’Œè§£æåŸå§‹æ•°æ®
2. ç®¡ç†æ•°æ®çš„ç”Ÿå‘½å‘¨æœŸ
3. æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆè¿‡æ»¤å·²å¤„ç†æ•°æ®ï¼‰
"""

import os
import random
from argparse import Namespace
from dataclasses import dataclass, field
from logging import Logger

from ..utils.utils import read_json


@dataclass
class DataPoint:
    """
    å•ä¸ªæ•°æ®ç‚¹ç±»
    
    è¡¨ç¤ºä¸€ä¸ªå¾…å¤„ç†çš„å›¾åƒ-é—®é¢˜å¯¹
    
    å±æ€§:
        image_id: å›¾åƒå”¯ä¸€æ ‡è¯†ç¬¦
        image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
        question: å…³äºå›¾åƒçš„é—®é¢˜/æç¤º
        attributes: é¢å¤–å±æ€§å­—å…¸ï¼ˆå¯æ‰©å±•ï¼‰
    """
    image_id: str           # å›¾åƒID
    image_path: str         # å›¾åƒè·¯å¾„
    question: str           # é—®é¢˜/æç¤ºè¯­
    attributes: dict[str] = field(default_factory=dict)  # æ‰©å±•å±æ€§

    def __getitem__(self, key: str) -> str:
        """æ”¯æŒå­—å…¸å¼è®¿é—®"""
        if key == "image_id":
            return self.image_id
        elif key == "image_path":
            return self.image_path
        elif key == "question":
            return self.question
        elif key in self.attributes:
            return self.attributes[key]
        else:
            raise KeyError(f"Key {key} not found in DataPoint")

    def __repr__(self) -> str:
        return f"DataPoint(image_id={self.image_id}, image_path={self.image_path}, question={self.question})"


@dataclass
class DataSet:
    """
    æ•°æ®é›†ç®¡ç†ç±»
    
    è´Ÿè´£åŠ è½½ã€ç®¡ç†å’Œè¿‡æ»¤æ•°æ®é›†
    
    å±æ€§:
        args: å‘½ä»¤è¡Œå‚æ•°
        logger: æ—¥å¿—è®°å½•å™¨
        data: æ•°æ®ç‚¹åˆ—è¡¨
    
    ä¸»è¦åŠŸèƒ½:
        1. ä»æ–‡ä»¶åŠ è½½æ•°æ®
        2. æ”¯æŒæ•°æ®é‡‡æ ·
        3. æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆè¿‡æ»¤å·²å¤„ç†æ•°æ®ï¼‰
    """
    args: Namespace
    logger: Logger | None = None
    data: list[DataPoint] = field(init=False)

    def __post_init__(self):
        """åˆå§‹åŒ–åè‡ªåŠ¨åŠ è½½æ•°æ®é›†"""
        if self.logger is not None and self.args is not None:
            self.logger.info(f"Loading dataset from {self.args.dataset_path}")
        self.data = self._load_dataset(self.args)

    def _load_dataset(self, args: Namespace) -> list[DataPoint]:
        """
        åŠ è½½æ•°æ®é›†
        
        å‚æ•°:
            args: åŒ…å«dataset_pathå’Œnum_of_dataçš„å‚æ•°å¯¹è±¡
        
        è¿”å›:
            DataPointåˆ—è¡¨
        
        å¤„ç†é€»è¾‘:
            1. ä»JSON/JSONLæ–‡ä»¶åŠ è½½åŸå§‹æ•°æ®
            2. å¦‚æœæŒ‡å®šäº†æ•°æ®é‡é™åˆ¶ï¼Œéšæœºé‡‡æ ·
            3. è½¬æ¢ä¸ºDataPointå¯¹è±¡
        """
        dataset_path: str = args.dataset_path
        assert os.path.exists(dataset_path), f"Dataset file not found at {dataset_path}"

        dataset: list[dict] = read_json(dataset_path)

        # æ•°æ®é‡‡æ ·ï¼šå¦‚æœnum_of_dataæœ‰æ•ˆä¸”å°äºæ€»é‡ï¼Œéšæœºé‡‡æ ·
        num_of_data: int = args.num_of_data
        if 0 <= num_of_data < len(dataset):
            random.seed(args.seed)  # ä¿è¯å¯å¤ç°
            dataset = random.sample(dataset, num_of_data)

        return [self._create_datapoint(item) for item in dataset]

    @staticmethod
    def _create_datapoint(item: dict) -> DataPoint:
        """
        ä»å­—å…¸åˆ›å»ºDataPointå¯¹è±¡
        
        æ”¯æŒå¤šç§æ•°æ®æ ¼å¼ï¼Œè‡ªåŠ¨é€‚é…å­—æ®µå
        """
        image_id: str = item["image_id"] if "image_id" in item else item["image"]
        image_path: str = item["image_path"] if "image_path" in item else item["image"]
        question: str = item["question"] if "question" in item else "Describe this image."
        
        # å…¶ä»–å­—æ®µä½œä¸ºæ‰©å±•å±æ€§
        attributes: dict[str] = {
            k: v for k, v in item.items() if k not in {"image_id", "image", "image_path", "question"}
        }
        return DataPoint(image_id, image_path, question, attributes=attributes)

    def filter(self, save_path: str) -> None:
        """
        è¿‡æ»¤å·²å¤„ç†çš„æ•°æ®ï¼ˆæ–­ç‚¹ç»­ä¼ åŠŸèƒ½ï¼‰
        
        å‚æ•°:
            save_path: å·²ä¿å­˜ç»“æœçš„æ–‡ä»¶è·¯å¾„
        
        åŠŸèƒ½:
            è¯»å–å·²ä¿å­˜çš„ç»“æœï¼Œä»æ•°æ®é›†ä¸­ç§»é™¤å·²å¤„ç†çš„æ•°æ®ç‚¹ï¼Œ
            ä½¿å¾—ç¨‹åºå¯ä»¥ä»ä¸­æ–­å¤„ç»§ç»­å¤„ç†
        """
        if not os.path.exists(save_path) or not os.path.isfile(save_path) or not self.data:
            return

        exist_data: list[dict] = read_json(save_path)
        done_image_id: list = [d["image_id"] for d in exist_data]
        # ä¿ç•™æœªå¤„ç†çš„æ•°æ®
        self.data = [d for d in self.data if d.image_id not in done_image_id]
```

---

### 3.4 æ•°æ®çŠ¶æ€ç®¡ç† (model/auxiliary/datastate.py)

```python
"""
datastate.py - æ•°æ®å¤„ç†çŠ¶æ€ç®¡ç†æ¨¡å—

å®šä¹‰äº†è·Ÿè¸ªæ•°æ®å¤„ç†è¿‡ç¨‹çš„çŠ¶æ€ç±»ï¼Œç”¨äºï¼š
1. ç»´æŠ¤å½“å‰å¤„ç†çš„ä¸Šä¸‹æ–‡
2. è®°å½•ç”Ÿæˆçš„å¥å­å’Œæ£€æµ‹åˆ°çš„å¯¹è±¡
3. ç®¡ç†å¹»è§‰/éå¹»è§‰å¯¹è±¡çš„åˆ†ç±»
"""

from dataclasses import dataclass, field
from PIL import Image
from model.detector.yolo_model import YoloResult
from .dataset import DataPoint


@dataclass
class DataState:
    """
    åŸºç¡€æ•°æ®çŠ¶æ€ç±»
    
    è·Ÿè¸ªå•ä¸ªæ•°æ®ç‚¹çš„å¤„ç†çŠ¶æ€
    
    å±æ€§:
        data: åŸå§‹æ•°æ®ç‚¹
        image_path: å›¾åƒè·¯å¾„
        image: åŠ è½½çš„å›¾åƒå¯¹è±¡
        question: é—®é¢˜/æç¤º
        is_finished: æ˜¯å¦å®Œæˆå¤„ç†
        assistant: å½“å‰ç”Ÿæˆçš„å®Œæ•´æè¿°
        nonhallu_objects: å·²ç¡®è®¤çœŸå®å­˜åœ¨çš„å¯¹è±¡åˆ—è¡¨
        uncertain_objects: ä¸ç¡®å®šçš„å¯¹è±¡åˆ—è¡¨
        hallu_objects: å·²ç¡®è®¤ä¸ºå¹»è§‰çš„å¯¹è±¡åˆ—è¡¨
    """
    data: DataPoint
    image_path: str = field(init=False)
    image: Image.Image = field(init=False)
    question: str = field(init=False)
    is_finished: bool = False           # å¤„ç†å®Œæˆæ ‡å¿—
    assistant: str = ""                  # å½“å‰ç”Ÿæˆçš„å›å¤
    
    # ä¸‰ç±»å¯¹è±¡ç¼“å­˜
    nonhallu_objects: list[str] = field(default_factory=list)   # éå¹»è§‰å¯¹è±¡
    uncertain_objects: list[str] = field(default_factory=list)  # ä¸ç¡®å®šå¯¹è±¡
    hallu_objects: list[str] = field(default_factory=list)      # å¹»è§‰å¯¹è±¡

    def __post_init__(self):
        """åˆå§‹åŒ–æ—¶åŠ è½½å›¾åƒ"""
        from run.utils import open_images
        self.image_path = self.data.image_path
        self.image = open_images(self.image_path)  # æ‰“å¼€å¹¶è½¬æ¢ä¸ºRGB
        self.question = self.data.question


@dataclass
class DataStateForBuildDataset(DataState):
    """
    ç”¨äºæ„å»ºè®­ç»ƒæ•°æ®é›†çš„æ•°æ®çŠ¶æ€ç±»
    
    ç»§æ‰¿è‡ªDataStateï¼Œæ·»åŠ äº†æ›´å¤šç”¨äºåå¥½å¯¹æ„å»ºçš„çŠ¶æ€ä¿¡æ¯
    
    æ ¸å¿ƒè®¾è®¡:
        è¿™ä¸ªç±»ç»´æŠ¤äº†æ•´ä¸ªè¿­ä»£å¼ç”Ÿæˆè¿‡ç¨‹çš„å®Œæ•´çŠ¶æ€ï¼ŒåŒ…æ‹¬ï¼š
        1. æ¯ä¸€æ­¥ç”Ÿæˆçš„æ‰€æœ‰å€™é€‰å¥å­
        2. æ¯ä¸ªå¥å­ä¸­æå–çš„å¯¹è±¡
        3. å¯¹è±¡çš„å¹»è§‰/éå¹»è§‰åˆ†ç±»
        4. æœ€ç»ˆé€‰æ‹©çš„å¥å­å½¢æˆçš„ä¸Šä¸‹æ–‡
    
    é‡è¦å±æ€§:
        yolo_detected: YOLOæ˜¯å¦å·²æ£€æµ‹è¿‡æ­¤å›¾åƒ
        yolo_result: YOLOæ£€æµ‹ç»“æœ
        detector_reject: è®°å½•è¢«å„æ£€æµ‹å™¨æ‹’ç»çš„å¯¹è±¡
        generated_sentences: æ¯æ­¥ç”Ÿæˆçš„å€™é€‰å¥å­åˆ—è¡¨
        generated_objects: æ¯æ­¥æ¯ä¸ªå€™é€‰å¥å­ä¸­çš„å¯¹è±¡
        generated_hallu_objects: æ¯æ­¥æ¯ä¸ªå€™é€‰å¥å­ä¸­çš„å¹»è§‰å¯¹è±¡
        generated_nonhallu_objects: æ¯æ­¥æ¯ä¸ªå€™é€‰å¥å­ä¸­çš„éå¹»è§‰å¯¹è±¡
    """
    # YOLOæ£€æµ‹ç›¸å…³
    yolo_detected: bool = False
    yolo_result: YoloResult = None

    # æ£€æµ‹å™¨æ‹’ç»è®°å½•ï¼šè®°å½•å“ªäº›å¯¹è±¡è¢«å“ªä¸ªæ£€æµ‹å™¨åˆ¤å®šä¸ºä¸å­˜åœ¨
    detector_reject: dict[str, list[str]] = field(init=False)
    
    # ç”Ÿæˆè¿‡ç¨‹è®°å½•
    # ç»“æ„: generated_sentences[step_idx] = [sent_1, sent_2, ..., sent_n]
    generated_sentences: list[list[str]] = field(default_factory=list)
    
    # è®°å½•æœ€ç»ˆé€‰å®šçš„assistantå¥å­
    generated_assistents: list[str] = field(default_factory=list)

    # å¯¹è±¡åˆ†æè®°å½•
    # ç»“æ„: generated_objects[step_idx][candidate_idx] = [obj_1, obj_2, ...]
    generated_objects: list[list[list[str]]] = field(default_factory=list)
    generated_hallu_objects: list[list[list[str]]] = field(default_factory=list)
    generated_nonhallu_objects: list[list[list[str]]] = field(default_factory=list)

    # å½“å‰assistantä¸­ç´¯ç§¯çš„å¯¹è±¡
    assistant_objects: list[str] = field(default_factory=list)
    assistant_hallu_objects: list[str] = field(default_factory=list)
    assistant_nonhallu_objects: list[str] = field(default_factory=list)

    # ç”¨äºPOPEæ•°æ®é›†æ„å»º
    ground_truth: bool = field(init=False)

    # è°ƒè¯•ä¿¡æ¯
    gt_objects: list[str] = field(default_factory=list)

    # éš¾æ ·æœ¬ç›¸å…³
    hard_positive: list[str] = field(default_factory=list)   # æœªè¢«æ¨¡å‹æåŠä½†ç¡®å®å­˜åœ¨çš„å¯¹è±¡
    small_objects: list[str] = field(default_factory=list)   # å°å¯¹è±¡
    edge_objects: list[str] = field(default_factory=list)    # è¾¹ç¼˜å¯¹è±¡

    # è‡ªç„¶ä¸Šä¸‹æ–‡ç¼“å­˜ï¼ˆè´ªå©ªæœç´¢ç”Ÿæˆï¼‰
    nature_context: str = None
    nature_objects: list[list[str]] = field(default_factory=list)
    nature_hallu_objects: list[list[str]] = field(default_factory=list)
    nature_nonhallu_objects: list[list[str]] = field(default_factory=list)

    def __post_init__(self):
        """åˆå§‹åŒ–ç‰¹æœ‰çŠ¶æ€"""
        super().__post_init__()
        self.generated_assistents.append("")  # ç¬¬ä¸€æ­¥éœ€è¦ç©ºå­—ç¬¦ä¸²
        self.detector_reject = {"dino": [], "yolo": []}  # åˆå§‹åŒ–æ£€æµ‹å™¨æ‹’ç»è®°å½•

        if "ground_truth" in self.data.attributes:
            self.ground_truth = self.data.attributes["ground_truth"]

    def app_assistant(self, new_sents: list[str], idx: int) -> None:
        """
        è¿½åŠ é€‰ä¸­çš„å¥å­åˆ°assistant
        
        å‚æ•°:
            new_sents: å½“å‰æ­¥éª¤çš„æ‰€æœ‰å€™é€‰å¥å­
            idx: é€‰ä¸­çš„å¥å­ç´¢å¼•
        
        åŠŸèƒ½:
            1. å°†é€‰ä¸­å¥å­è¿½åŠ åˆ°assistant
            2. è®°å½•assistantå†å²
            3. æ›´æ–°assistantä¸­çš„å¯¹è±¡åˆ—è¡¨
        """
        # æ‹¼æ¥æ–°å¥å­åˆ°ç°æœ‰assistant
        self.assistant = self.assistant + " " + new_sents[idx] if self.assistant else new_sents[idx]
        self.generated_assistents.append(self.assistant)

        # æ›´æ–°assistantä¸­çš„å¯¹è±¡ç»Ÿè®¡
        if len(self.generated_objects) == self.gen_sents_cnt:
            self.assistant_objects.extend(self.generated_objects[-1][idx])
        if len(self.generated_hallu_objects) == self.gen_sents_cnt:
            self.assistant_hallu_objects.extend(self.generated_hallu_objects[-1][idx])
        if len(self.generated_nonhallu_objects) == self.gen_sents_cnt:
            self.assistant_nonhallu_objects.extend(self.generated_nonhallu_objects[-1][idx])

    @property
    def gen_sents_cnt(self) -> int:
        """è¿”å›å·²ç”Ÿæˆçš„å¥å­æ­¥æ•°"""
        return len(self.generated_sentences)

    @property
    def now_step_idx(self) -> int:
        """è¿”å›å½“å‰æ­¥éª¤ç´¢å¼•ï¼ˆ0-basedï¼‰"""
        return self.gen_sents_cnt - 1

    @property
    def context_gen_objects(self) -> set[str]:
        """è¿”å›ä¸Šä¸‹æ–‡ä¸­å·²ç”Ÿæˆçš„æ‰€æœ‰å¯¹è±¡ï¼ˆå»é‡ï¼‰"""
        return set(self.assistant_objects)

    @property
    def context_gen_hallu_objects(self) -> set[str]:
        """è¿”å›ä¸Šä¸‹æ–‡ä¸­å·²ç”Ÿæˆçš„å¹»è§‰å¯¹è±¡ï¼ˆå»é‡ï¼‰"""
        return set(self.assistant_hallu_objects)

    @property
    def flat_gen_objs(self) -> list[str]:
        """è¿”å›æ‰€æœ‰ç”Ÿæˆè¿‡ç¨‹ä¸­æåŠçš„å¯¹è±¡ï¼ˆæœªå»é‡ï¼‰"""
        return [obj for objs in self.generated_objects for obj_list in objs for obj in obj_list]

    def gen_objs(self, index: int) -> list[list[str]]:
        """è·å–æŒ‡å®šæ­¥éª¤çš„æ‰€æœ‰å€™é€‰å¥å­çš„å¯¹è±¡"""
        return self.generated_objects[index]

    def hallu_objs(self, index: int) -> list[list[str]]:
        """è·å–æŒ‡å®šæ­¥éª¤çš„æ‰€æœ‰å€™é€‰å¥å­çš„å¹»è§‰å¯¹è±¡"""
        return self.generated_hallu_objects[index]

    def nonhallu_objs(self, index: int) -> list[list[str]]:
        """è·å–æŒ‡å®šæ­¥éª¤çš„æ‰€æœ‰å€™é€‰å¥å­çš„éå¹»è§‰å¯¹è±¡"""
        return self.generated_nonhallu_objects[index]
```

---

### 3.5 è¿è¡Œå…¥å£ (run/run.py)

```python
"""
run.py - è¿è¡Œå…¥å£æ¨¡å—

è´Ÿè´£åˆå§‹åŒ–æ•°æ®é›†å¹¶å¯åŠ¨ç”Ÿæˆæµç¨‹
"""

def run() -> None:
    """
    ä¸»è¿è¡Œå‡½æ•°
    
    æ‰§è¡Œæµç¨‹:
        1. å¯¼å…¥å¿…è¦çš„æ¨¡å—å’Œå…¨å±€å˜é‡
        2. åŠ è½½æ•°æ®é›†
        3. è¿‡æ»¤å·²å¤„ç†çš„æ•°æ®ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
        4. è°ƒç”¨æ•°æ®é›†ç”Ÿæˆå‡½æ•°
    """
    from model.auxiliary.dataset import DataSet
    from model.auxiliary.global_vars import GVars
    from run.generate_dataset import run_gen_dataset

    args, save_path, logger = GVars.args, GVars.save_path, GVars.logger
    batch_size = args.batch_size

    logger.info(f"Current batch size: {batch_size}")
    logger.info(f"Start loading dataset with dataset path: {args.dataset_path}")
    
    # åˆ›å»ºæ•°æ®é›†å¹¶è¿‡æ»¤å·²å¤„ç†çš„æ•°æ®
    dataset: DataSet = DataSet(args=args, logger=logger)
    dataset.filter(save_path)  # æ–­ç‚¹ç»­ä¼ ï¼šç§»é™¤å·²å¤„ç†çš„æ•°æ®
    
    logger.info(f"Finish loading dataset, dataset size: {len(dataset.data)}")

    if not dataset.data:
        logger.info("All data has been processed, exit run function")
        return
        
    # å¯åŠ¨æ•°æ®é›†ç”Ÿæˆ
    run_gen_dataset(dataset.data, batch_size)
```

---

### 3.6 æ•°æ®é›†ç”Ÿæˆæ ¸å¿ƒ (run/generate_dataset.py)

```python
"""
generate_dataset.py - æ•°æ®é›†ç”Ÿæˆæ ¸å¿ƒæ¨¡å—

è¿™æ˜¯SENTINELé¡¹ç›®çš„æ ¸å¿ƒé€»è¾‘ï¼Œè´Ÿè´£ï¼š
1. è¿­ä»£å¼åœ°ç”Ÿæˆå›¾åƒæè¿°
2. è¯†åˆ«å¹»è§‰å¯¹è±¡å’ŒçœŸå®å¯¹è±¡
3. æ„å»ºåå¥½æ•°æ®å¯¹ç”¨äºDPOè®­ç»ƒ

æ ¸å¿ƒç®—æ³•:
    å¯¹äºæ¯å¼ å›¾åƒï¼Œå¾ªç¯æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ç›´åˆ°ç”Ÿæˆç»“æŸ:
    1. ä½¿ç”¨VLMç”Ÿæˆå¤šä¸ªå€™é€‰å¥å­ï¼ˆé‡‡æ ·n=10ï¼‰
    2. ä»å¥å­ä¸­æå–å¯¹è±¡
    3. ä½¿ç”¨YOLOå’ŒDINOéªŒè¯å¯¹è±¡æ˜¯å¦å­˜åœ¨
    4. æ„å»ºåå¥½å¯¹ï¼šéå¹»è§‰å¥å­ vs å¹»è§‰å¥å­
    5. é€‰æ‹©æœ€ä½³å¥å­ä½œä¸ºä¸‹ä¸€è½®ä¸Šä¸‹æ–‡
"""

import random
from time import time

from model.auxiliary.dataset import DataPoint
from model.auxiliary.datastate import DataStateForBuildDataset
from model.auxiliary.global_vars import GVars
from model.detector.grounding_dino import DINO
from model.detector.yolo_model import YoloModel
from model.others.sg_parser import SGParser
from model.others.spacy_model import SpacyModel
from model.others.wordnet import WordnetModel
from model.utils.gen_utils import GenOutput, get_generator
from run.utils import (
    b_get_hallu_objects,
    extract_obj_from_textgraphs,
    extract_obj_w_gt,
    get_finish_flag,
    log_progress,
    object_in_set,
    objects_in_set,
    refModel,
    resolve_corefs,
    save_result,
    yolo_detect,
)

DEBUG = True           # è°ƒè¯•æ¨¡å¼
HALLUCI_CONTEXT = False  # æ˜¯å¦ä½¿ç”¨å«å¹»è§‰çš„å¥å­æ·»åŠ åˆ°context
CHECK_TYPE = "any"     # å¯¹è±¡æ£€æŸ¥ç±»å‹


def save_data_state(
    res_save_path: str,
    s: DataStateForBuildDataset,
    spacy: SpacyModel | None = None,
    wn: WordnetModel | None = None,
    inv_synonym_map: dict[str, list[str]] | None = None,
) -> None:
    """
    ä¿å­˜æ•°æ®çŠ¶æ€åˆ°æ–‡ä»¶
    
    å‚æ•°:
        res_save_path: ä¿å­˜è·¯å¾„
        s: æ•°æ®çŠ¶æ€å¯¹è±¡
        spacy: Spacyæ¨¡å‹ï¼ˆç”¨äºåŒä¹‰è¯æ£€æŸ¥ï¼‰
        wn: WordNetæ¨¡å‹
        inv_synonym_map: é€†åŒä¹‰è¯æ˜ å°„
    
    ä¿å­˜å†…å®¹:
        - åŸºæœ¬ä¿¡æ¯ï¼šimage_id, image_path, question, caption
        - ç»Ÿè®¡ä¿¡æ¯ï¼šå¥å­æ•°é‡ã€å¹»è§‰å¯¹è±¡ã€éå¹»è§‰å¯¹è±¡
        - åˆ†æä¿¡æ¯ï¼šå›°éš¾æ­£ä¾‹ã€å°å¯¹è±¡ã€è¾¹ç¼˜å¯¹è±¡
    """
    # å›°éš¾æ­£ä¾‹ï¼šå›¾åƒä¸­å­˜åœ¨ä½†æ¨¡å‹æœªæåŠçš„å¯¹è±¡
    s.hard_positive = [
        obj for obj in s.yolo_result.labels 
        if not object_in_set(obj, set(s.flat_gen_objs), spacy, wn, inv_synonym_map)
    ]
    
    # å°å¯¹è±¡ï¼šé¢ç§¯å°äº2%çš„éå¹»è§‰å¯¹è±¡
    s.small_objects = [
        obj
        for obj in s.yolo_result.labels
        if object_in_set(obj, set(s.flat_nonhallu_objs), spacy, wn, inv_synonym_map)
        and s.yolo_result.get_largest(obj)
        and (s.yolo_result.get_largest(obj)["xywhn"][2] * s.yolo_result.get_largest(obj)["xywhn"][3] < 0.02)
    ]
    
    # è¾¹ç¼˜å¯¹è±¡ï¼šè·ç¦»å›¾åƒè¾¹ç¼˜å°äº10%çš„éå¹»è§‰å¯¹è±¡
    s.edge_objects = [
        obj
        for obj in s.yolo_result.labels
        if object_in_set(obj, set(s.flat_nonhallu_objs), spacy, wn, inv_synonym_map)
        if s.yolo_result.get_farthest_to_edge(obj)
        and (
            min(
                s.yolo_result.get_farthest_to_edge(obj)["xywhn"][0],
                1 - s.yolo_result.get_farthest_to_edge(obj)["xywhn"][0],
                s.yolo_result.get_farthest_to_edge(obj)["xywhn"][1],
                1 - s.yolo_result.get_farthest_to_edge(obj)["xywhn"][1],
            )
            < 0.1
        )
    ]

    save_result(
        res_save_path,
        {
            "image_id": s.data.image_id,
            "image_path": s.data.image_path,
            "question": s.question,
            "caption": s.assistant,
            "sentences_cnt": s.gen_sents_cnt,
            "hallu_objects": s.hallu_objects,
            "uncertain_objects": s.uncertain_objects,
            "nonhallu_objects": s.nonhallu_objects,
            "hard_positive": s.hard_positive,
            "small_objects": s.small_objects,
            "edge_objects": s.edge_objects,
        },
    )


def maybe_build_pair(
    save_path: str,
    s: DataStateForBuildDataset,
    spacy: SpacyModel,
    wn: WordnetModel,
    inv_synonym_map: dict[str, list[str]] | None = None,
) -> int:
    """
    æ„å»ºåå¥½æ•°æ®å¯¹å¹¶è¿”å›æœ€ä½³å¥å­ç´¢å¼•
    
    å‚æ•°:
        save_path: ä¿å­˜è·¯å¾„
        s: æ•°æ®çŠ¶æ€
        spacy: Spacyæ¨¡å‹
        wn: WordNetæ¨¡å‹
        inv_synonym_map: é€†åŒä¹‰è¯æ˜ å°„
    
    è¿”å›:
        æœ€ä½³å¥å­çš„ç´¢å¼•ï¼ˆç”¨äºæ›´æ–°ä¸Šä¸‹æ–‡ï¼‰
    
    æ ¸å¿ƒé€»è¾‘:
        1. åˆ†ç±»å€™é€‰å¥å­ï¼šéå¹»è§‰å¥å­ vs å¹»è§‰å¥å­
        2. è¿›ä¸€æ­¥åˆ†ç±»éå¹»è§‰å¥å­ï¼šæ¢ç´¢æ–°å¯¹è±¡çš„ vs é‡å¤æ—§å¯¹è±¡çš„
        3. é…å¯¹æ„å»ºåå¥½å¯¹ï¼šy+ (éå¹»è§‰) vs y- (å¹»è§‰)
        4. é€‰æ‹©ç­–ç•¥ï¼šä¼˜å…ˆé€‰æ‹©æ¢ç´¢æ–°å¯¹è±¡çš„éå¹»è§‰å¥å­
    """
    
    def create_pairs(win_candidates: list[tuple[int, list[str]]], lose_candidates, pair_type: str) -> list[dict]:
        """æ„å»ºåå¥½æ•°æ®å¯¹"""
        return [
            {
                "image_id": s.data.image_id,
                "image_path": s.data.image_path,
                "question": s.data.question,
                "context": s.assistant,           # å½“å‰ä¸Šä¸‹æ–‡
                "y_win": new_sentences[win_idx],  # èƒœå‡ºå¥å­ï¼ˆéå¹»è§‰ï¼‰
                "y_lose": new_sentences[lose_idx], # å¤±è´¥å¥å­ï¼ˆå¹»è§‰ï¼‰
                # é™„åŠ åˆ†æä¿¡æ¯
                "nonhallu_objects": s.nonhallu_objects,
                "context_gen_objects": s.context_gen_objects,
                "context_gen_hallu_objects": s.context_gen_hallu_objects,
                "objects_of_y_win": objects,
                "hallu_objects_of_y_lose": hallu_objects,
                "is_last_sent": s.is_finished,
                "type": pair_type,
            }
            for (win_idx, objects), (lose_idx, hallu_objects) in zip(win_candidates, lose_candidates)
        ]

    new_sentences: list[str] = s.generated_sentences[-1]
    if len(new_sentences) <= 1:
        return 0

    step_idx = s.now_step_idx
    # è·å–å½“å‰æ­¥éª¤æ‰€æœ‰å€™é€‰å¥å­çš„å¯¹è±¡ä¿¡æ¯
    objects_list, nonhallu_objects_list, hallu_objects_list = (
        s.gen_objs(step_idx),
        s.nonhallu_objs(step_idx),
        s.hallu_objs(step_idx),
    )

    # ç­›é€‰éå¹»è§‰å€™é€‰ï¼šè‡³å°‘æœ‰ä¸€ä¸ªå¯¹è±¡ä¸”æ— å¹»è§‰å¯¹è±¡ä¸”ä¸åœ¨ä¸ç¡®å®šåˆ—è¡¨ä¸­
    nonhallu_candidates: list = [
        (i, objects)
        for i, (objects, hallu_objects) in enumerate(zip(objects_list, hallu_objects_list))
        if len(objects) >= 1
        and not hallu_objects
        and not objects_in_set(objects, s.uncertain_objects, spacy, wn, inv_synonym_map, check_type="any")
    ]
    
    # ç­›é€‰å¹»è§‰å€™é€‰ï¼šåŒ…å«è‡³å°‘ä¸€ä¸ªå¹»è§‰å¯¹è±¡
    hallu_candidates: list = [
        (i, hallu_objects) for i, hallu_objects in enumerate(hallu_objects_list) if len(hallu_objects) >= 1
    ]

    # å°†éå¹»è§‰å€™é€‰è¿›ä¸€æ­¥åˆ†ä¸ºï¼šæˆåŠŸæ¢ç´¢æ–°å¯¹è±¡çš„ vs é‡å¤æ—§å¯¹è±¡çš„
    success_explore_candidates, normal_nonhallu_candidates = [], []
    for idx, objects in nonhallu_candidates:
        if not objects_in_set(objects, s.context_gen_objects, spacy, wn, inv_synonym_map, check_type=CHECK_TYPE):
            # æ¢ç´¢äº†ä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰çš„æ–°å¯¹è±¡
            success_explore_candidates.append((idx, objects))
        else:
            # åªæåŠä¸Šä¸‹æ–‡ä¸­å·²æœ‰çš„å¯¹è±¡
            normal_nonhallu_candidates.append((idx, objects))

    # æ„å»ºåå¥½å¯¹ï¼šæ•°é‡å–ä¸¤è€…æœ€å°å€¼
    num_pairs = min(len(normal_nonhallu_candidates), len(hallu_candidates))
    all_results_list = create_pairs(normal_nonhallu_candidates[:num_pairs], hallu_candidates[:num_pairs], "y+")

    # ä¿å­˜åå¥½å¯¹
    save_result(save_path.replace(".jsonl", "_data_pair.jsonl"), all_results_list)

    # é€‰æ‹©æœ€ä½³å¥å­ç”¨äºä¸‹ä¸€è½®ç”Ÿæˆ
    if HALLUCI_CONTEXT:
        # æµ‹è¯•ç”¨ï¼šæ•…æ„é€‰æ‹©å¹»è§‰å¥å­
        if hallu_candidates:
            return random.choice([idx for idx, _ in hallu_candidates])
        else:
            return random.choice(range(len(new_sentences)))
    else:
        # æ­£å¸¸ç­–ç•¥ï¼šä¼˜å…ˆæ¢ç´¢æ–°å¯¹è±¡ï¼Œå…¶æ¬¡é€‰æ‹©éå¹»è§‰å¥å­
        if success_explore_candidates:
            return random.choice([idx for idx, _ in success_explore_candidates])
        elif normal_nonhallu_candidates:
            return random.choice([i for i, _ in normal_nonhallu_candidates])
        else:
            return random.choice(range(len(new_sentences)))


def run_gen_dataset(datalist: list[DataPoint], batch_size: int) -> None:
    """
    ä¸»æ•°æ®é›†ç”Ÿæˆå‡½æ•°
    
    å‚æ•°:
        datalist: å¾…å¤„ç†çš„æ•°æ®ç‚¹åˆ—è¡¨
        batch_size: æ‰¹å¤„ç†å¤§å°
    
    ä¸»å¾ªç¯é€»è¾‘:
        while è¿˜æœ‰æœªå¤„ç†çš„æ•°æ®:
            1. è£…è½½batch_sizeä¸ªæ•°æ®åˆ°çŠ¶æ€åˆ—è¡¨
            2. å¯¹æ–°æ•°æ®è¿›è¡ŒYOLOæ£€æµ‹
            3. ä½¿ç”¨VLMç”Ÿæˆå€™é€‰å¥å­ï¼ˆé‡‡æ ·n=10ï¼‰
            4. æ£€æŸ¥ç”Ÿæˆæ˜¯å¦ç»“æŸ
            5. æ‰§è¡ŒæŒ‡ä»£æ¶ˆè§£
            6. æå–å¯¹è±¡ï¼ˆä½¿ç”¨GTè¯è¡¨ + åœºæ™¯å›¾è§£æï¼‰
            7. åˆ¤æ–­å¹»è§‰å¯¹è±¡ï¼ˆYOLO + DINOäº¤å‰éªŒè¯ï¼‰
            8. æ„å»ºåå¥½å¯¹å¹¶é€‰æ‹©æœ€ä½³å¥å­
            9. ä¿å­˜å®Œæˆçš„æ•°æ®ï¼Œç§»é™¤å·²å®ŒæˆçŠ¶æ€
    """
    logger, save_path, model_dir, alter_device = GVars.logger, GVars.save_path, GVars.model_dir, GVars.alter_device
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨ï¼ˆVLMæ¨¡å‹ï¼‰
    generator = get_generator(use_vllm=True, debug=DEBUG)

    # åˆå§‹åŒ–ç›®æ ‡æ£€æµ‹å™¨
    DINO_detector = DINO("base", model_dir=model_dir, device=alter_device, logger=logger)
    yolo = YoloModel("yolo11x", model_dir=model_dir, logger=logger)

    # åˆå§‹åŒ–NLPå·¥å…·
    SG_parser = SGParser(DEBUG, "base", model_dir, device=alter_device, logger=logger)  # åœºæ™¯å›¾è§£æ
    spacy = SpacyModel(model_size="md", model_dir=model_dir, device=alter_device, logger=logger)  # è¯æ€§åˆ†æ
    wn = WordnetModel(logger=logger)  # WordNetåŒä¹‰è¯
    ref = refModel(args=GVars.args)  # å‚è€ƒæ¨¡å‹ï¼ˆåŒ…å«æœ‰æ•ˆåè¯åˆ—è¡¨ï¼‰

    data_states: list[DataStateForBuildDataset] = []  # å½“å‰æ­£åœ¨å¤„ç†çš„æ•°æ®çŠ¶æ€
    num_of_data, finished_data_num = len(datalist), 0

    logger.info(f"Start processing {num_of_data} data points.")

    # ä¸»å¾ªç¯
    while len(datalist) > 0 or len(data_states) > 0:
        start_time = time()

        # æ­¥éª¤1: è£…è½½æ•°æ®åˆ°çŠ¶æ€åˆ—è¡¨ï¼Œä¿æŒbatch_sizeä¸ªæ´»è·ƒçŠ¶æ€
        while len(data_states) < batch_size and len(datalist) > 0:
            tmp_data = datalist.pop(0)
            data_states.append(DataStateForBuildDataset(data=tmp_data))

        # æ­¥éª¤2: å¯¹æ–°å›¾åƒè¿›è¡ŒYOLOæ£€æµ‹ï¼ˆåªæ£€æµ‹ä¸€æ¬¡ï¼‰
        yolo_detect(yolo, data_states)

        # æ­¥éª¤3: ä½¿ç”¨VLMç”Ÿæˆå€™é€‰å¥å­
        # é‡‡æ ·å‚æ•°ï¼šn=10ï¼ˆæ¯ä¸ªæ ·æœ¬ç”Ÿæˆ10ä¸ªå€™é€‰ï¼‰ï¼Œtemp=0.7ï¼Œå•å¥å­ç”Ÿæˆ
        out: GenOutput = generator.gen(
            images=[s.image for s in data_states],
            users=[s.question for s in data_states],
            assistants=[s.assistant for s in data_states],  # ä½¿ç”¨ç´¯ç§¯çš„ä¸Šä¸‹æ–‡
            do_sample=True,
            n=10,           # æ¯ä¸ªæ ·æœ¬ç”Ÿæˆ10ä¸ªå€™é€‰å¥å­
            temp=0.7,       # é‡‡æ ·æ¸©åº¦
            force_list=True,
            single_sentence=True,  # åªç”Ÿæˆä¸€ä¸ªå¥å­
        )
        b_new_sents: list[list[str]] = out.outputs

        # æ­¥éª¤4: æ£€æŸ¥æ˜¯å¦ç”Ÿæˆç»“æŸ
        for idx, (new_sents, s) in enumerate(zip(b_new_sents, data_states)):
            b_new_sents[idx], s.is_finished = get_finish_flag(new_sents, remove_duplicates=True)

        # æ­¥éª¤5: æ‰§è¡ŒæŒ‡ä»£æ¶ˆè§£
        # å°†ä»£è¯æ›¿æ¢ä¸ºå…¶æŒ‡ä»£çš„åè¯ï¼Œä¾¿äºåç»­å¯¹è±¡æå–
        context = [s.assistant for s in data_states]
        b_resolved_new_sents: list[list[str]] = resolve_corefs(spacy, b_new_sents, context, 1)

        # æ­¥éª¤6: æå–å¯¹è±¡
        b_object_lists: list[list[list[str]]] = []
        for s, new_sents in zip(data_states, b_resolved_new_sents):
            # æ–¹æ³•1: åŸºäºGTè¯è¡¨çš„å¯¹è±¡æå–
            object_lists: list[list[str]] = extract_obj_w_gt(
                new_sents,
                ref.valid_nouns,
                ref.double_words,
                ref.inv_syn_map,
                wn,
                force_list=True,
                return_repr=False,
            )

            # æ–¹æ³•2: åŸºäºåœºæ™¯å›¾è§£æçš„å¯¹è±¡æå–
            textgraphs: list[list[list[str]]] = SG_parser.pharse(new_sents, force_list=True)
            new_object_lists: list[list[str]] = extract_obj_from_textgraphs(textgraphs, spacy, wn, force_list=True)
            
            # åˆå¹¶ä¸¤ç§æ–¹æ³•çš„ç»“æœ
            object_lists = [objects + new_objects for objects, new_objects in zip(object_lists, new_object_lists)]
            b_object_lists.append(object_lists)

        # æ­¥éª¤7: åˆ¤æ–­å¹»è§‰å¯¹è±¡ï¼ˆæ ¸å¿ƒï¼šYOLO + DINOäº¤å‰éªŒè¯ï¼‰
        b_haluci_objects_list, b_nonhallu_objects_list = b_get_hallu_objects(
            b_object_lists,
            [s.nonhallu_objects for s in data_states],    # å·²çŸ¥éå¹»è§‰å¯¹è±¡
            [s.hallu_objects for s in data_states],       # å·²çŸ¥å¹»è§‰å¯¹è±¡
            spacy=spacy,
            wn=wn,
            images=[s.image for s in data_states],
            dino=DINO_detector,
            b_yolo_results=[s.yolo_result.labels for s in data_states] if yolo else None,
            yolo_labels=yolo.labels if yolo else None,
            b_uncertain_objects=[s.uncertain_objects for s in data_states],
            b_detector_rejects=[s.detector_reject for s in data_states],
            inv_syn_map=ref.inv_syn_map,
        )

        # æ­¥éª¤8: æ›´æ–°çŠ¶æ€å¹¶æ„å»ºåå¥½å¯¹
        for s, new_sents, object_lists, haluci_objects_list, nonhallu_objects_list in zip(
            data_states, b_resolved_new_sents, b_object_lists, b_haluci_objects_list, b_nonhallu_objects_list
        ):
            if not new_sents:
                continue
            # è®°å½•ç”Ÿæˆç»“æœ
            s.generated_sentences.append(new_sents)
            s.generated_objects.append(object_lists)
            s.generated_hallu_objects.append(haluci_objects_list)
            s.generated_nonhallu_objects.append(nonhallu_objects_list)

            # æ„å»ºåå¥½å¯¹å¹¶é€‰æ‹©æœ€ä½³å¥å­
            best_idx: int = maybe_build_pair(save_path, s, spacy, wn, ref.inv_syn_map)
            s.app_assistant(new_sents, best_idx)  # å°†æœ€ä½³å¥å­è¿½åŠ åˆ°ä¸Šä¸‹æ–‡

        # æ­¥éª¤9: ä¿å­˜å¹¶æ¸…ç†å·²å®Œæˆçš„çŠ¶æ€
        [save_data_state(save_path, s, spacy, wn, ref.inv_syn_map) for s in data_states if s.is_finished]

        finished_data_num += len([s for s in data_states if s.is_finished])
        log_progress(logger, finished_data_num, num_of_data, batch_size, time() - start_time)
        data_states = [s for s in data_states if not s.is_finished]  # åªä¿ç•™æœªå®Œæˆçš„çŠ¶æ€
```

---

### 3.7 å·¥å…·å‡½æ•° (run/utils.py) - éƒ¨åˆ†å…³é”®å‡½æ•°

```python
"""
utils.py - è¿è¡Œå·¥å…·å‡½æ•°æ¨¡å—

åŒ…å«æ•°æ®å¤„ç†è¿‡ç¨‹ä¸­ä½¿ç”¨çš„å„ç§è¾…åŠ©å‡½æ•°
"""

@dataclass
class refModel:
    """
    å‚è€ƒæ¨¡å‹ç±»
    
    å­˜å‚¨ç”¨äºå¯¹è±¡è¯†åˆ«çš„å‚è€ƒæ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
    - valid_nouns: æœ‰æ•ˆåè¯åˆ—è¡¨ï¼ˆMSCOCOå¯¹è±¡ï¼‰
    - inv_syn_map: åŒä¹‰è¯åˆ°ä»£è¡¨è¯çš„æ˜ å°„
    - double_words: åŒè¯çŸ­è¯­çš„æ˜ å°„
    """
    args: Namespace
    valid_nouns: list[str] = field(init=False)
    inv_syn_map: dict[str, str] = field(init=False)
    double_words: dict[str, str] = field(init=False)

    def __post_init__(self):
        self.valid_nouns, self.inv_syn_map, self.double_words = self._get_nouns()

    def _get_nouns(self) -> tuple[list[str], dict[str, str], dict[str, str]]:
        """è·å–MSCOCOå¯¹è±¡è¯è¡¨å’ŒåŒä¹‰è¯æ˜ å°„"""
        mscoco_objects, inverse_syn_map = get_object_n_represent()
        valid_nouns: list[str] = mscoco_objects
        double_word_dict = get_double_word_dict()
        return valid_nouns, inverse_syn_map, double_word_dict


def get_hallu_objects(
    objects_list: list[list[str]],
    nonhallu_objects: list[str] | None,
    hallu_objects: list[str],
    spacy: SpacyModel,
    wn: WordnetModel,
    image: Image.Image | None = None,
    dino: DINO | None = None,
    yolo_results: list[str] | None = None,
    yolo_labels: list[str] | None = None,
    uncertain_objects: list[str] | None = None,
    detector_reject: dict[str, list[str]] | None = None,
    inv_syn_map: dict[str, str] | None = None,
) -> tuple[list[list[str]], list[list[str]]]:
    """
    æ ¸å¿ƒå‡½æ•°ï¼šåˆ¤æ–­å¯¹è±¡æ˜¯å¦ä¸ºå¹»è§‰
    
    åˆ¤æ–­ç­–ç•¥ï¼ˆYOLO + DINOäº¤å‰éªŒè¯ï¼‰ï¼š
    1. å¦‚æœå¯¹è±¡å·²åœ¨ç¼“å­˜ä¸­ï¼ˆå·²ç¡®è®¤ä¸ºå¹»è§‰/éå¹»è§‰/ä¸ç¡®å®šï¼‰ï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜ç»“æœ
    2. å¯¹äºæ–°å¯¹è±¡ï¼š
       - YOLOè®¤å¯ AND DINOè®¤å¯ â†’ éå¹»è§‰å¯¹è±¡
       - YOLOä¸è®¤å¯ AND DINOä¸è®¤å¯ â†’ å¹»è§‰å¯¹è±¡
       - å…¶ä»–æƒ…å†µ â†’ ä¸ç¡®å®šå¯¹è±¡
    
    ç‰¹æ®Šå¤„ç†ï¼š
    - å¦‚æœå¯¹è±¡ä¸åœ¨YOLOçš„æ£€æµ‹èŒƒå›´å†…ï¼ˆä¸åœ¨æ ‡ç­¾åˆ—è¡¨ä¸­ï¼‰ï¼Œè§†ä¸ºYOLOè®¤å¯
    - è¿™æ ·å¯ä»¥å¤„ç†YOLOæ— æ³•æ£€æµ‹çš„å¯¹è±¡ç±»åˆ«
    
    å‚æ•°:
        objects_list: æ‰€æœ‰å€™é€‰å¥å­çš„å¯¹è±¡åˆ—è¡¨
        nonhallu_objects: å·²ç¡®è®¤çš„éå¹»è§‰å¯¹è±¡ï¼ˆä¼šè¢«æ›´æ–°ï¼‰
        hallu_objects: å·²ç¡®è®¤çš„å¹»è§‰å¯¹è±¡ï¼ˆä¼šè¢«æ›´æ–°ï¼‰
        å…¶ä»–å‚æ•°: æ£€æµ‹å™¨å’ŒNLPå·¥å…·
    
    è¿”å›:
        (å¹»è§‰å¯¹è±¡åˆ—è¡¨, éå¹»è§‰å¯¹è±¡åˆ—è¡¨) - å¯¹åº”æ¯ä¸ªå€™é€‰å¥å­
    """
    # ... è¯¦ç»†å®ç°è§æºä»£ç  ...


def resolve_corefs(
    spacy: SpacyModel,
    descriptions: list[str] | list[list[str]],
    previous: list[str],
    retro_num: int,
    force_list: bool = True,
) -> list[str] | list[list[str]]:
    """
    æŒ‡ä»£æ¶ˆè§£å‡½æ•°
    
    å°†ä»£è¯æ›¿æ¢ä¸ºå…¶æŒ‡ä»£çš„å…·ä½“åè¯ï¼Œä¾‹å¦‚ï¼š
    "A man is sitting. He is holding a book." 
    â†’ "A man is sitting. A man is holding a book."
    
    è¿™å¯¹äºå‡†ç¡®æå–å¯¹è±¡è‡³å…³é‡è¦
    
    å‚æ•°:
        spacy: Spacyæ¨¡å‹ï¼ˆå¸¦fastcorefç»„ä»¶ï¼‰
        descriptions: å½“å‰å¥å­
        previous: ä¸Šä¸‹æ–‡å¥å­
        retro_num: å›æº¯å¥å­æ•°é‡
    """
    # ... è¯¦ç»†å®ç°è§æºä»£ç  ...


def object_in_set(
    obj: str,
    target_set: list[str] | set[str],
    spacy: SpacyModel,
    wn: WordnetModel,
    inv_synonym_map: dict[str, str] | None = None,
    allow_synonym: bool = False,
) -> bool:
    """
    æ£€æŸ¥å¯¹è±¡æ˜¯å¦åœ¨ç›®æ ‡é›†åˆä¸­
    
    åŒ¹é…ç­–ç•¥ï¼š
    1. ç›´æ¥åŒ¹é…ä»£è¡¨è¯
    2. è¯å¹²åŒ¹é…ï¼ˆlemmaï¼‰
    3. å¯é€‰ï¼šåŒä¹‰è¯åŒ¹é…
    """
    # ... è¯¦ç»†å®ç°è§æºä»£ç  ...
```

---

## 4. æ¨¡å‹æ¨¡å—è¯¦è§£

### 4.1 è§†è§‰è¯­è¨€æ¨¡å‹ç”Ÿæˆå™¨

#### LLaVAæ¨¡å‹ (model/generator/llava.py)

```python
"""
llava.py - LLaVAæ¨¡å‹å°è£…

æ”¯æŒLLaVA v1.5å’Œv1.6ç‰ˆæœ¬ï¼Œæä¾›ç»Ÿä¸€çš„ç”Ÿæˆæ¥å£
å¯ä»¥é€‰æ‹©ä½¿ç”¨vLLMï¼ˆé«˜æ•ˆï¼‰æˆ–HuggingFaceï¼ˆæ ‡å‡†ï¼‰åç«¯
"""

class LlavaModel:
    """
    LLaVAæ¨¡å‹å°è£…ç±»
    
    åˆå§‹åŒ–å‚æ•°:
        use_vllm: æ˜¯å¦ä½¿ç”¨vLLMåç«¯ï¼ˆæ¨èï¼Œæ›´é«˜æ•ˆï¼‰
        version: æ¨¡å‹ç‰ˆæœ¬ "1.5" æˆ– "1.6"
        model_size: æ¨¡å‹å¤§å° "7b" æˆ– "13b"
        gpu_util: GPUæ˜¾å­˜åˆ©ç”¨ç‡
    
    ä¸»è¦æ–¹æ³•:
        gen(): ç”Ÿæˆå“åº”
    """
    
    def gen(
        self,
        images: Image.Image | list[Image.Image],
        users: str | list[str],
        assistants: str | list[str] = "",
        do_sample: bool = False,
        n: int = 1,
        temp: float = 0.3,
        max_tokens: int = 512,
        single_sentence: bool = False,
    ) -> list[str] | list[list[str]]:
        """
        ç”Ÿæˆå“åº”
        
        å‚æ•°:
            images: è¾“å…¥å›¾åƒ
            users: ç”¨æˆ·é—®é¢˜/æç¤º
            assistants: å·²æœ‰çš„assistantå“åº”ï¼ˆç”¨äºç»­å†™ï¼‰
            do_sample: æ˜¯å¦é‡‡æ ·ï¼ˆTrue=å¤šæ ·æ€§ï¼ŒFalse=è´ªå©ªï¼‰
            n: æ¯ä¸ªæ ·æœ¬ç”Ÿæˆnä¸ªå€™é€‰
            temp: é‡‡æ ·æ¸©åº¦
            single_sentence: æ˜¯å¦åªç”Ÿæˆå•ä¸ªå¥å­
        
        è¿”å›:
            ç”Ÿæˆçš„æ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨
        """
        # ... å®ç°ç»†èŠ‚ ...
```

### 4.2 ç›®æ ‡æ£€æµ‹å™¨

#### Grounding DINO (model/detector/grounding_dino.py)

```python
"""
grounding_dino.py - Grounding DINOç›®æ ‡æ£€æµ‹å™¨

Grounding DINOæ˜¯ä¸€ä¸ªå¼€æ”¾è¯æ±‡çš„ç›®æ ‡æ£€æµ‹å™¨ï¼Œå¯ä»¥æ ¹æ®æ–‡æœ¬æè¿°æ£€æµ‹ä»»æ„å¯¹è±¡
ä¸YOLOé…åˆä½¿ç”¨è¿›è¡Œäº¤å‰éªŒè¯
"""

class DINO:
    """
    Grounding DINOæ£€æµ‹å™¨å°è£…
    
    ç‰¹ç‚¹:
        - å¼€æ”¾è¯æ±‡ï¼šå¯ä»¥æ£€æµ‹ä»»æ„æ–‡æœ¬æè¿°çš„å¯¹è±¡
        - æ”¯æŒæ‰¹é‡æ£€æµ‹
        - æä¾›ç½®ä¿¡åº¦é˜ˆå€¼æ§åˆ¶
    """
    
    def detect(
        self,
        images: Image.Image | list[Image.Image],
        captions: str | list[str],
        box_threshold=0.35,
        text_threshold=0.25,
    ) -> list[dict[str]] | dict[str]:
        """
        æ£€æµ‹å¯¹è±¡
        
        å‚æ•°:
            images: è¾“å…¥å›¾åƒ
            captions: è¦æ£€æµ‹çš„å¯¹è±¡æè¿°ï¼ˆæ ¼å¼: "cat.dog.person."ï¼‰
            box_threshold: è¾¹ç•Œæ¡†ç½®ä¿¡åº¦é˜ˆå€¼
            text_threshold: æ–‡æœ¬åŒ¹é…ç½®ä¿¡åº¦é˜ˆå€¼
        
        è¿”å›:
            æ£€æµ‹ç»“æœå­—å…¸ï¼ŒåŒ…å« scores, boxes, labels
        """
        # ... å®ç°ç»†èŠ‚ ...
```

#### YOLOæ£€æµ‹å™¨ (model/detector/yolo_model.py)

```python
"""
yolo_model.py - YOLOç›®æ ‡æ£€æµ‹å™¨

ä½¿ç”¨YOLO11xè¿›è¡Œå°é—­è¯æ±‡çš„ç›®æ ‡æ£€æµ‹
æä¾›80ç±»COCOå¯¹è±¡çš„é«˜ç²¾åº¦æ£€æµ‹
"""

@dataclass
class YoloResult:
    """
    YOLOæ£€æµ‹ç»“æœå°è£…
    
    æä¾›ä¾¿æ·çš„ç»“æœæŸ¥è¯¢æ¥å£ï¼š
        - labels: æ£€æµ‹åˆ°çš„æ‰€æœ‰æ ‡ç­¾ï¼ˆå»é‡ï¼‰
        - get_largest(): è·å–æŸç±»åˆ«ä¸­æœ€å¤§çš„å¯¹è±¡
        - get_smallest(): è·å–æŸç±»åˆ«ä¸­æœ€å°çš„å¯¹è±¡
        - get_closest_to_edge(): è·å–æœ€æ¥è¿‘è¾¹ç¼˜çš„å¯¹è±¡
    """
    original_result: Results
    result: dict[str, list[dict[str]]] = field(default_factory=dict)


class YoloModel:
    """
    YOLOæ¨¡å‹å°è£…
    
    æ”¯æŒæ¨¡å‹:
        - yolo11x: æœ€æ–°æœ€å‡†ç¡®
        - yolov8x-worldv2: æ”¯æŒå¼€æ”¾è¯æ±‡
    """
    
    @property
    def labels(self) -> list[str]:
        """è¿”å›æ¨¡å‹æ”¯æŒçš„æ‰€æœ‰ç±»åˆ«æ ‡ç­¾"""
        return list(self.yolo.names.values())
    
    def predict(self, images: Image.Image | list[Image.Image]) -> list[YoloResult]:
        """æ‰§è¡Œæ£€æµ‹å¹¶è¿”å›ç»“æœ"""
        # ... å®ç°ç»†èŠ‚ ...
```

### 4.3 NLPå·¥å…·

#### Spacyæ¨¡å‹ (model/others/spacy_model.py)

```python
"""
spacy_model.py - Spacy NLPå·¥å…·å°è£…

æä¾›ä»¥ä¸‹åŠŸèƒ½:
1. æŒ‡ä»£æ¶ˆè§£ï¼ˆä½¿ç”¨fastcorefï¼‰
2. è¯æ€§æ ‡æ³¨
3. è¯å¹²æå–
4. åè¯æå–
"""

class SpacyModel:
    """
    Spacy NLPæ¨¡å‹å°è£…
    
    ä¸»è¦åŠŸèƒ½:
        resolve_coref(): æŒ‡ä»£æ¶ˆè§£
        is_noun(): åˆ¤æ–­æ˜¯å¦ä¸ºåè¯
        lemma(): è¯å¹²æå–
        extract_nouns_from_text(): ä»æ–‡æœ¬æå–åè¯
    """
    
    def resolve_coref(self, text: list[str] | str) -> list[str] | str:
        """
        æŒ‡ä»£æ¶ˆè§£
        
        å°†ä»£è¯æ›¿æ¢ä¸ºå…¶æŒ‡ä»£çš„å…·ä½“åè¯
        ä¾‹å¦‚: "He is eating." â†’ "The man is eating."
        """
        # å»¶è¿ŸåŠ è½½fastcorefç»„ä»¶
        if not self._loaded_fastcoref:
            self._load_fastcoref()
        # ... å®ç°ç»†èŠ‚ ...
    
    def lemma(self, word: str) -> str:
        """
        è¯å¹²æå–
        
        è·å–å•è¯çš„è¯å¹²å½¢å¼
        ä¾‹å¦‚: "running" â†’ "run", "dogs" â†’ "dog"
        """
        # ... å®ç°ç»†èŠ‚ ...
```

#### åœºæ™¯å›¾è§£æå™¨ (model/others/sg_parser.py)

```python
"""
sg_parser.py - åœºæ™¯å›¾è§£æå™¨

ä½¿ç”¨T5æ¨¡å‹å°†è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºç»“æ„åŒ–çš„åœºæ™¯å›¾ï¼ˆä¸‰å…ƒç»„ï¼‰
ç”¨äºæ›´å‡†ç¡®åœ°æå–å¥å­ä¸­çš„å¯¹è±¡å’Œå…³ç³»
"""

class SGParser:
    """
    åœºæ™¯å›¾è§£æå™¨
    
    å°†å¥å­è§£æä¸º(ä¸»è¯­, è°“è¯­, å®¾è¯­)ä¸‰å…ƒç»„
    ä¾‹å¦‚: "A man is holding a book" â†’ [("man", "holding", "book")]
    """
    
    def pharse(self, discriptions: list[str] | str) -> list[list[list[str]]]:
        """
        è§£æå¥å­ä¸ºåœºæ™¯å›¾
        
        è¾“å…¥: å¥å­åˆ—è¡¨
        è¾“å‡º: ä¸‰å…ƒç»„åˆ—è¡¨çš„åˆ—è¡¨
        """
        # ... å®ç°ç»†èŠ‚ ...
```

---

## 5. æ•°æ®æµç¨‹å›¾

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    SENTINEL æ•°æ®æµç¨‹                      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. åˆå§‹åŒ–é˜¶æ®µ                                                                    â”‚
â”‚  â”œâ”€â”€ åŠ è½½ç¯å¢ƒå˜é‡ (.env)                                                          â”‚
â”‚  â”œâ”€â”€ è§£æå‘½ä»¤è¡Œå‚æ•°                                                               â”‚
â”‚  â”œâ”€â”€ åˆå§‹åŒ–å…¨å±€å˜é‡ (GVars)                                                       â”‚
â”‚  â”œâ”€â”€ åŠ è½½ç”Ÿæˆå™¨ (LLaVA/Qwen2-VL)                                                  â”‚
â”‚  â”œâ”€â”€ åŠ è½½æ£€æµ‹å™¨ (YOLO + Grounding DINO)                                           â”‚
â”‚  â””â”€â”€ åŠ è½½NLPå·¥å…· (Spacy, WordNet, SG Parser)                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. æ•°æ®åŠ è½½é˜¶æ®µ                                                                  â”‚
â”‚  â”œâ”€â”€ è¯»å–æ•°æ®é›† (image_data.jsonl)                                                â”‚
â”‚  â”œâ”€â”€ è¿‡æ»¤å·²å¤„ç†æ•°æ® (æ–­ç‚¹ç»­ä¼ )                                                    â”‚
â”‚  â””â”€â”€ åˆ›å»ºDataPointåˆ—è¡¨                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. è¿­ä»£ç”Ÿæˆå¾ªç¯ (æ¯æ‰¹batch_sizeä¸ªæ ·æœ¬)                                           â”‚
â”‚                                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3.1 è£…è½½æ•°æ®                                                              â”‚   â”‚
â”‚  â”‚      åˆ›å»ºDataStateForBuildDatasetå¯¹è±¡                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                            â”‚
â”‚                                      â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3.2 YOLOé¢„æ£€æµ‹                                                            â”‚   â”‚
â”‚  â”‚      å¯¹æ¯å¼ å›¾åƒæ‰§è¡ŒYOLOæ£€æµ‹ï¼Œç¼“å­˜ç»“æœ                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                            â”‚
â”‚                                      â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3.3 å€™é€‰å¥å­ç”Ÿæˆ                                                          â”‚   â”‚
â”‚  â”‚      VLMç”Ÿæˆn=10ä¸ªå€™é€‰å¥å­ (é‡‡æ ·temp=0.7)                                   â”‚   â”‚
â”‚  â”‚      è¾“å…¥: å›¾åƒ + é—®é¢˜ + å½“å‰ä¸Šä¸‹æ–‡                                         â”‚   â”‚
â”‚  â”‚      è¾“å‡º: 10ä¸ªå€™é€‰ä¸‹ä¸€å¥                                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                            â”‚
â”‚                                      â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3.4 æŒ‡ä»£æ¶ˆè§£                                                              â”‚   â”‚
â”‚  â”‚      ä½¿ç”¨Spacy+fastcorefè§£æä»£è¯                                            â”‚   â”‚
â”‚  â”‚      "He" â†’ "The man"                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                            â”‚
â”‚                                      â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3.5 å¯¹è±¡æå–                                                              â”‚   â”‚
â”‚  â”‚      æ–¹æ³•1: åŸºäºMSCOCOè¯è¡¨çš„åŒ¹é…                                            â”‚   â”‚
â”‚  â”‚      æ–¹æ³•2: åœºæ™¯å›¾è§£æ (T5æ¨¡å‹)                                              â”‚   â”‚
â”‚  â”‚      åˆå¹¶ç»“æœå¾—åˆ°æ¯ä¸ªå€™é€‰å¥å­çš„å¯¹è±¡åˆ—è¡¨                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                            â”‚
â”‚                                      â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3.6 å¹»è§‰åˆ¤æ–­ (æ ¸å¿ƒ!)                                                       â”‚   â”‚
â”‚  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚      â”‚  å¯¹äºæ¯ä¸ªæ–°æåˆ°çš„å¯¹è±¡:                                           â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  â”œâ”€â”€ YOLOæ£€æµ‹: å¯¹è±¡æ˜¯å¦åœ¨YOLOç»“æœä¸­?                             â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  â”‚   (å¦‚æœä¸åœ¨YOLOç±»åˆ«ä¸­ï¼Œè§†ä¸ºé€šè¿‡)                              â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  â”œâ”€â”€ DINOæ£€æµ‹: ä½¿ç”¨Grounding DINOéªŒè¯                            â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  â”‚                                                               â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  â””â”€â”€ åˆ¤å®šé€»è¾‘:                                                   â”‚  â”‚   â”‚
â”‚  â”‚      â”‚      â”œâ”€â”€ YOLOâœ“ AND DINOâœ“ â†’ éå¹»è§‰å¯¹è±¡                           â”‚  â”‚   â”‚
â”‚  â”‚      â”‚      â”œâ”€â”€ YOLOâœ— AND DINOâœ— â†’ å¹»è§‰å¯¹è±¡                             â”‚  â”‚   â”‚
â”‚  â”‚      â”‚      â””â”€â”€ å…¶ä»–æƒ…å†µ â†’ ä¸ç¡®å®šå¯¹è±¡                                   â”‚  â”‚   â”‚
â”‚  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                            â”‚
â”‚                                      â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3.7 åå¥½å¯¹æ„å»º                                                            â”‚   â”‚
â”‚  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚      â”‚  åˆ†ç±»å€™é€‰å¥å­:                                                   â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  â”œâ”€â”€ éå¹»è§‰å€™é€‰: æœ‰å¯¹è±¡ä¸”æ— å¹»è§‰å¯¹è±¡                              â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  â”‚   â”œâ”€â”€ æ¢ç´¢å‹: åŒ…å«ä¸Šä¸‹æ–‡ä¸­æœªå‡ºç°çš„æ–°å¯¹è±¡ â˜…ä¼˜å…ˆ                â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  â”‚   â””â”€â”€ é‡å¤å‹: åªæåŠå·²æœ‰å¯¹è±¡                                  â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  â””â”€â”€ å¹»è§‰å€™é€‰: åŒ…å«å¹»è§‰å¯¹è±¡                                      â”‚  â”‚   â”‚
â”‚  â”‚      â”‚                                                                   â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  æ„å»ºåå¥½å¯¹:                                                      â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  y_win (èƒœå‡º) = éå¹»è§‰å¥å­                                        â”‚  â”‚   â”‚
â”‚  â”‚      â”‚  y_lose (å¤±è´¥) = å¹»è§‰å¥å­                                         â”‚  â”‚   â”‚
â”‚  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                            â”‚
â”‚                                      â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3.8 æ›´æ–°ä¸Šä¸‹æ–‡                                                            â”‚   â”‚
â”‚  â”‚      é€‰æ‹©æœ€ä½³å¥å­è¿½åŠ åˆ°assistant                                            â”‚   â”‚
â”‚  â”‚      é€‰æ‹©ç­–ç•¥: ä¼˜å…ˆæ¢ç´¢å‹ > é‡å¤å‹ > éšæœº                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                            â”‚
â”‚                                      â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  3.9 æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶                                                          â”‚   â”‚
â”‚  â”‚      å¦‚æœ>50%çš„å€™é€‰ä¸ºç©º â†’ æ ‡è®°å®Œæˆ                                          â”‚   â”‚
â”‚  â”‚      å¦åˆ™ â†’ ç»§ç»­ä¸‹ä¸€è½®è¿­ä»£                                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                            â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                         â–¼                          â–¼                              â”‚
â”‚                    [æœªå®Œæˆ]                   [å·²å®Œæˆ]                            â”‚
â”‚                    ç»§ç»­è¿­ä»£                   ä¿å­˜ç»“æœ                            â”‚
â”‚                         â”‚                          â”‚                              â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                    â”‚                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. è¾“å‡ºæ–‡ä»¶                                                                     â”‚
â”‚  â”œâ”€â”€ <model_name>.jsonl                                                          â”‚
â”‚  â”‚   åŒ…å«: image_id, caption, hallu_objects, nonhallu_objectsç­‰                  â”‚
â”‚  â”‚                                                                               â”‚
â”‚  â””â”€â”€ <model_name>_data_pair.jsonl                                                â”‚
â”‚      åŒ…å«: image_path, question, context, y_win, y_lose                          â”‚
â”‚      ç”¨äºDPOè®­ç»ƒçš„åå¥½å¯¹æ•°æ®                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. å…³é”®ç®—æ³•è§£æ

### 6.1 å¹»è§‰æ£€æµ‹ç®—æ³•

```
è¾“å…¥: å¯¹è±¡åˆ—è¡¨ objects, å·²çŸ¥éå¹»è§‰å¯¹è±¡ nonhallu, å·²çŸ¥å¹»è§‰å¯¹è±¡ hallu
è¾“å‡º: æ›´æ–°åçš„ nonhallu, hallu, ä»¥åŠæ¯ä¸ªå¥å­çš„åˆ†ç±»ç»“æœ

ç®—æ³•æµç¨‹:
1. è·å–ç¼“å­˜å¯¹è±¡ cached = nonhallu âˆª hallu âˆª uncertain
2. è·å–æœªç¼“å­˜å¯¹è±¡ uncached = objects - cached

3. å¯¹äºæ¯ä¸ª obj âˆˆ uncached:
   a. yolo_ok = (obj âˆˆ YOLOæ£€æµ‹ç»“æœ) OR (obj âˆ‰ YOLOæ ‡ç­¾é›†)
   b. dino_ok = DINO.detect(image, obj) è¿”å›éç©ºç»“æœ
   
   c. åˆ¤å®š:
      if yolo_ok AND dino_ok:
          nonhallu.add(obj)  # ç¡®è®¤å­˜åœ¨
      elif NOT yolo_ok AND NOT dino_ok:
          hallu.add(obj)     # ç¡®è®¤å¹»è§‰
      else:
          uncertain.add(obj) # æ£€æµ‹å™¨ä¸ä¸€è‡´

4. è¿”å›åˆ†ç±»ç»“æœ
```

### 6.2 åå¥½å¯¹æ„å»ºç®—æ³•

```
è¾“å…¥: å€™é€‰å¥å­é›†åˆ S, å½“å‰ä¸Šä¸‹æ–‡ C
è¾“å‡º: åå¥½å¯¹åˆ—è¡¨, æœ€ä½³å¥å­ç´¢å¼•

ç®—æ³•æµç¨‹:
1. å¯¹æ¯ä¸ªå¥å­ s âˆˆ S:
   a. æå–å¯¹è±¡: objs = extract_objects(s)
   b. åˆ†ç±»å¯¹è±¡: hallu_objs, nonhallu_objs = classify(objs)
   
2. åˆ†ç±»å¥å­:
   a. éå¹»è§‰å¥å­: nonhallu_sents = {s | hallu_objs(s) = âˆ… AND objs(s) â‰  âˆ…}
   b. å¹»è§‰å¥å­: hallu_sents = {s | hallu_objs(s) â‰  âˆ…}

3. è¿›ä¸€æ­¥åˆ†ç±»éå¹»è§‰å¥å­:
   a. æ¢ç´¢å‹: explore = {s | objs(s) âˆ© context_objs = âˆ…}
   b. é‡å¤å‹: repeat = nonhallu_sents - explore

4. æ„å»ºåå¥½å¯¹:
   pairs = zip(repeat, hallu_sents)  # y_win=éå¹»è§‰, y_lose=å¹»è§‰

5. é€‰æ‹©æœ€ä½³å¥å­:
   if explore â‰  âˆ…:
       return random.choice(explore)  # ä¼˜å…ˆæ¢ç´¢æ–°å¯¹è±¡
   elif repeat â‰  âˆ…:
       return random.choice(repeat)   # å…¶æ¬¡é€‰éå¹»è§‰
   else:
       return random.choice(S)        # éšæœºé€‰æ‹©
```

### 6.3 ä¸Šä¸‹æ–‡è¿­ä»£å¼•å¯¼ç®—æ³•

```
ç®—æ³•æ ¸å¿ƒæ€æƒ³:
é€šè¿‡é€‰æ‹©éå¹»è§‰å¥å­ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œå¼•å¯¼æ¨¡å‹åœ¨åç»­ç”Ÿæˆä¸­é¿å…å¹»è§‰

è¿­ä»£è¿‡ç¨‹:
Context_0 = ""
for step in range(max_steps):
    candidates = VLM.generate(Image, Question, Context_{step-1}, n=10)
    
    # åˆ†ç±»å€™é€‰
    nonhallu, hallu = classify_candidates(candidates)
    
    # æ„å»ºåå¥½å¯¹ç”¨äºè®­ç»ƒ
    pairs.append({
        "context": Context_{step-1},
        "y_win": nonhallu[random],
        "y_lose": hallu[random]
    })
    
    # é€‰æ‹©æœ€ä½³å¥å­æ›´æ–°ä¸Šä¸‹æ–‡
    best = select_best(nonhallu, explore_first=True)
    Context_{step} = Context_{step-1} + best
    
    if generation_finished:
        break

å…³é”®æ´å¯Ÿ:
- é€šè¿‡é€‰æ‹©éå¹»è§‰å¥å­ï¼Œä¸Šä¸‹æ–‡é€æ¸ç´¯ç§¯çœŸå®ä¿¡æ¯
- è¿™ç§ç´¯ç§¯ä½¿å¾—åç»­ç”Ÿæˆæ›´ä¸å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼ˆåˆ©ç”¨ä¸Šä¸‹æ–‡ä¸€è‡´æ€§ï¼‰
- åå¥½å¯¹æ•è·äº†"ç»™å®šç›¸åŒä¸Šä¸‹æ–‡ï¼Œé€‰æ‹©éå¹»è§‰è¾“å‡º"çš„åå¥½
```

---

## 7. ä½¿ç”¨è¯´æ˜

### 7.1 ç”Ÿæˆè®­ç»ƒæ•°æ®

```bash
# åŸºæœ¬ç”¨æ³•
python main.py

# æŒ‡å®šæ¨¡å‹
python main.py --model LLaVA_v1_5_7b

# æŒ‡å®šæ‰¹å¤„ç†å¤§å°
python main.py --batch_size 10

# æŒ‡å®šæ•°æ®é‡
python main.py --num_of_data 1000
```

### 7.2 è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼

```bash
# è½¬æ¢ä¸ºLLaMA-Factoryæ ¼å¼
python utils/get_llama_factory_data_pair.py

# è½¬æ¢ä¸ºLLaVA-v1.5æ ¼å¼
python utils/get_llava_v15_data_pair.py
```

### 7.3 å…³é”®é…ç½®

```python
# generate_dataset.py ä¸­çš„é…ç½®
DEBUG = True           # è°ƒè¯•æ¨¡å¼ï¼ˆä¸ç¼–è¯‘æ¨¡å‹ï¼‰
HALLUCI_CONTEXT = False  # æ˜¯å¦ä½¿ç”¨å¹»è§‰å¥å­æ›´æ–°ä¸Šä¸‹æ–‡
CHECK_TYPE = "any"     # å¯¹è±¡æ£€æŸ¥ç±»å‹

# ç”Ÿæˆå‚æ•°
n = 10                 # æ¯æ­¥ç”Ÿæˆå€™é€‰æ•°
temp = 0.7             # é‡‡æ ·æ¸©åº¦
single_sentence = True # å•å¥ç”Ÿæˆ
```

---

## 8. æ€»ç»“

SENTINELé¡¹ç›®é€šè¿‡ä»¥ä¸‹åˆ›æ–°ç‚¹è§£å†³VLMå¹»è§‰é—®é¢˜ï¼š

1. **å¥å­çº§æ—©æœŸå¹²é¢„**: åœ¨æ¯ä¸ªå¥å­ç”Ÿæˆåç«‹å³æ£€æµ‹å’Œå¹²é¢„
2. **æ£€æµ‹å™¨äº¤å‰éªŒè¯**: ä½¿ç”¨YOLOå’ŒDINOåŒé‡éªŒè¯å‡å°‘è¯¯åˆ¤
3. **è¿­ä»£å¼ä¸Šä¸‹æ–‡æ„å»º**: é€šè¿‡é€‰æ‹©éå¹»è§‰å¥å­ç´¯ç§¯å¯é ä¸Šä¸‹æ–‡
4. **æ— éœ€äººå·¥æ ‡æ³¨**: å®Œå…¨è‡ªåŠ¨åŒ–çš„åå¥½æ•°æ®æ„å»ºæµç¨‹

é¡¹ç›®æ¶æ„æ¸…æ™°ï¼Œæ¨¡å—åŒ–ç¨‹åº¦é«˜ï¼Œæ˜“äºæ‰©å±•åˆ°æ–°çš„VLMæ¨¡å‹ã€‚
